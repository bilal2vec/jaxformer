{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    seq_len: int\n",
    "    d_model: int\n",
    "    n_heads: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, mask, training):\n",
    "        seq_len = x.shape[1]\n",
    "        d_k = self.d_model // self.n_heads\n",
    "\n",
    "        q = nn.Dense(self.d_model)(x)\n",
    "        k = nn.Dense(self.d_model)(x)\n",
    "        v = nn.Dense(self.d_model)(x)\n",
    "\n",
    "        q = q.reshape((-1, seq_len, self.n_heads, d_k)).transpose((0, 2, 1, 3))\n",
    "        k = k.reshape((-1, seq_len, self.n_heads, d_k)).transpose((0, 2, 1, 3))\n",
    "        v = v.reshape((-1, seq_len, self.n_heads, d_k)).transpose((0, 2, 1, 3))\n",
    "\n",
    "        a = jnp.matmul(q, k.transpose((0, 1, 3, 2))) / jnp.sqrt(d_k)\n",
    "\n",
    "        mask = jnp.where(mask, 0, -jnp.inf)\n",
    "        a += mask\n",
    "\n",
    "        a = nn.softmax(a, axis=-1)\n",
    "        a = nn.Dropout(0.1)(a, deterministic=not training)\n",
    "        a = jnp.matmul(a, v)\n",
    "\n",
    "        return a.transpose((0, 2, 1, 3)).reshape(-1, self.seq_len, self.d_model)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    d_model: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, training):\n",
    "        x = nn.Dense(self.d_model * 4)(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dense(self.d_model)(x)\n",
    "        x = nn.Dropout(0.1)(x, deterministic=not training)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    seq_len: int\n",
    "    d_model: int\n",
    "    n_heads: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, mask, training):\n",
    "\n",
    "        x = x + MultiHeadSelfAttention(self.seq_len, self.d_model,\n",
    "                                       self.n_heads)(nn.LayerNorm()(x), mask, training)\n",
    "        x = x + nn.Dropout(0.1)(MLP(self.d_model)(nn.LayerNorm()\n",
    "                                                  (x), training), deterministic=not training)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    seq_len: int\n",
    "    n_layers: int\n",
    "    vocab_size: int\n",
    "    d_model: int\n",
    "    n_heads: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, training=False):\n",
    "\n",
    "\n",
    "        position_ids = jnp.arange(start=0, stop=self.seq_len, step=1)\n",
    "        mask = jnp.triu(jnp.ones((1, self.seq_len, self.seq_len)), k=1) == 0\n",
    "\n",
    "        content_embedding = nn.Embed(self.vocab_size, self.d_model)\n",
    "        embeddings = content_embedding(x) + nn.Embed(self.seq_len, self.d_model)(position_ids)\n",
    "        x = nn.Dropout(0.1)(embeddings)\n",
    "\n",
    "        for _ in range(self.n_layers):\n",
    "            x = Block(self.seq_len, self.d_model,\n",
    "                      self.n_heads)(x, mask, training)\n",
    "\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = content_embedding.attend(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 128\n",
    "n_layers = 2\n",
    "vocab_size = 1024\n",
    "d_model = 768\n",
    "n_heads = 8\n",
    "\n",
    "d_k = d_model // n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "rng, dropout_rng = jax.random.split(rng)\n",
    "\n",
    "x = jax.random.randint(rng, (batch_size, seq_len), 0, 1000, jnp.int32)\n",
    "\n",
    "variables = GPT2(seq_len, n_layers, vocab_size, d_model, n_heads).init({'params': rng, 'dropout': dropout_rng}, x, training=False)\n",
    "gpt2 = GPT2(seq_len, n_layers, vocab_size, d_model, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(variables, batch, rng):\n",
    "    x = batch[:, :-1]\n",
    "    y = batch[:, 1:]\n",
    "    y = jax.nn.one_hot(y, vocab_size)\n",
    "\n",
    "    y_hat = gpt2.apply(variables, x, training=True, rngs={'dropout': rng})\n",
    "\n",
    "    loss = jnp.sum(y * jax.nn.log_softmax(y_hat, axis=-1), axis=-1)\n",
    "    return -jnp.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @partial(jax.pmap, axis_name='batch')\n",
    "def train_step(optimizer, batch, rng):\n",
    "    rng, rng_dropout = jax.random.split(rng)\n",
    "\n",
    "    loss, grad = jax.value_and_grad(loss_fn)(optimizer.target, batch, rng_dropout)\n",
    "\n",
    "    # loss = jax.lax.pmean(loss, axis_name='batch')\n",
    "    # grad = jax.lax.pmean(grad, axis_name='batch')\n",
    "\n",
    "    optimizer = optimizer.apply_gradient(grad)\n",
    "\n",
    "    return optimizer, loss, rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = flax.optim.Adam(learning_rate=1e-4, beta1=0.5, beta2=0.9).create(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.randint(rng, (batch_size, seq_len + 1), 0, 1000, jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, loss, rng = train_step(optimizer, x, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray(7.443428, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gpt2.apply(optimizer.target, x[:, :-1], training=True, rngs={'dropout': rng})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = jnp.argmax(nn.softmax(out, axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[371, 334, 451, 105, 244, 150, 707, 243, 501,  16, 627, 855,\n",
       "              260, 138,  28, 626,  69, 934, 893, 146, 213, 556, 391, 170,\n",
       "              391, 779, 957, 951, 239, 550, 451, 654,  18, 630, 278, 614,\n",
       "               73, 424, 527, 503, 736, 970, 603, 707, 367, 458, 449, 159,\n",
       "              949, 749,  15, 895, 523, 999,  89, 462, 957, 870, 898,  23,\n",
       "              299, 339, 385, 109, 104, 678, 298, 178, 303, 617, 650, 485,\n",
       "              391, 619, 941, 778, 122, 466, 634, 918, 871, 954, 848, 328,\n",
       "              743, 244, 345,  17,  38, 775, 317, 283, 458, 838, 557, 121,\n",
       "              396, 856, 761, 284, 234, 426, 541, 616, 873, 336, 671, 499,\n",
       "               13, 784, 844, 225, 347, 412, 558, 714, 567, 926,  12, 864,\n",
       "               92, 755, 417, 961, 998, 773,  18, 576],\n",
       "             [400, 485, 625, 796, 682, 296, 637, 415,  68, 778, 977, 593,\n",
       "              114, 305, 929, 118, 698, 735, 628, 932,   0, 424, 117, 684,\n",
       "              874, 141, 113, 216, 169, 833, 116, 394, 487,  75,  36, 830,\n",
       "              433, 609,  72, 909, 681,   3, 993, 451,  91, 498, 226, 360,\n",
       "              635, 335, 665, 736, 585, 698, 624, 683, 136, 375,  80, 866,\n",
       "              353, 662, 803,  63, 249, 780, 165, 821, 468, 311, 249, 534,\n",
       "              453,  79, 542, 131, 848, 609, 516, 420, 200, 214, 665,  23,\n",
       "              560, 568, 494, 783, 209, 816, 428, 511,  56, 152, 202, 199,\n",
       "              562, 590, 235,   9, 750, 240, 582, 364, 278, 111, 504, 756,\n",
       "              511, 499, 438, 451, 766, 873, 500, 604, 799, 477, 241, 826,\n",
       "              970, 779,  76, 389, 599, 707,  46, 542]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Buffer([[662, 371, 334, 451, 105, 244, 150, 707, 243, 501,  16, 627, 855,\n",
       "         260, 138,  28, 626,  69, 934, 893, 146, 213, 556, 391, 170, 391,\n",
       "         779, 957, 951, 239, 550, 451, 654,  18, 630, 278, 614,  73, 424,\n",
       "         527, 503, 736, 970, 603, 707, 367, 458, 449, 159, 949, 749,  15,\n",
       "         895, 523, 999,  89, 462, 957, 870, 898,  23, 299, 339, 385, 109,\n",
       "         104, 678, 298, 178, 303, 617, 650, 485, 391, 619, 941, 778, 122,\n",
       "         466, 634, 918, 871, 954, 848, 328, 743, 244, 345,  17,  38, 775,\n",
       "         317, 283, 458, 838, 557, 121, 396, 856, 761, 284, 234, 426, 541,\n",
       "         616, 873, 336, 671, 499,  13, 784, 844, 225, 347, 412, 558, 714,\n",
       "         567, 926,  12, 864,  92, 755, 417, 961, 998, 773,  18, 576],\n",
       "        [586, 400, 485, 625, 796, 682, 296, 637, 415,  68, 778, 977, 593,\n",
       "         114, 305, 929, 118, 698, 735, 628, 932,   0, 424, 117, 684, 874,\n",
       "         141, 113, 216, 169, 833, 116, 394, 487,  75,  36, 830, 433, 609,\n",
       "          72, 909, 681,   3, 993, 451,  91, 498, 226, 360, 635, 335, 665,\n",
       "         736, 585, 698, 624, 683, 136, 375,  80, 866, 353, 662, 803,  63,\n",
       "         249, 780, 165, 821, 468, 311, 249, 534, 453,  79, 542, 131, 848,\n",
       "         609, 516, 420, 200, 214, 665,  23, 560, 568, 494, 783, 209, 816,\n",
       "         428, 511,  56, 152, 202, 199, 562, 590, 235,   9, 750, 240, 582,\n",
       "         364, 278, 111, 504, 756, 511, 499, 438, 451, 766, 873, 500, 604,\n",
       "         799, 477, 241, 826, 970, 779,  76, 389, 599, 707,  46, 542]],       dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True],\n",
       "             [ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True,  True,  True,  True,  True,  True,  True,  True]],            dtype=bool)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "out2 == x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}